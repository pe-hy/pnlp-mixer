{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid/miniconda3/envs/to_cpp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from model import PnlpMixerSeqCls, PnlpMixerTokenCls\n",
    "from mixer import FFFTrainFixed\n",
    "from dataset import PnlpMixerDataModule\n",
    "from run import PnlpMixerSeqClsTrainModule, PnlpMixerTokenClsTrainModule\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('cfg/imdb_base.yml')\n",
    "\n",
    "def get_module_cls(type: str): \n",
    "    if type == 'mtop': \n",
    "        return PnlpMixerTokenClsTrainModule\n",
    "    if type == 'matis' or type == 'imdb': \n",
    "        return PnlpMixerSeqClsTrainModule\n",
    "\n",
    "module_cls = get_module_cls(cfg.train.dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'to_cpp/ffft_256_4/model.ckpt'\n",
    "orig_module = module_cls.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    optimizer_cfg=cfg.train.optimizer,\n",
    "    model_cfg=cfg.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = PnlpMixerDataModule(cfg.vocab, cfg.train, cfg.model.projection)\n",
    "data_module.setup('test')\n",
    "\n",
    "orig_module.eval()\n",
    "\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "\n",
    "batch = next(iter(test_dataloader))\n",
    "\n",
    "device = next(orig_module.parameters()).device\n",
    "batch = {k: v.to(device) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"batch.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(batch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"batch.pkl\", \"rb\") as f:\n",
    "#     batch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "Batch Accuracy: 0.8828\n",
      "Time: 2.0069186687469482\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    logits = orig_module.model(batch['inputs'])\n",
    "    end = time.time()\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predictions, batch['targets'])):\n",
    "    predicted_label = cfg.train.labels[pred.item()]\n",
    "    true_label = cfg.train.labels[target.item()]\n",
    "    # print(f\"Sample {i}:\")\n",
    "    # print(f\"  Predicted: {predicted_label}\")\n",
    "    # print(f\"  Actual: {true_label}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = (predictions == batch['targets']).float().mean()\n",
    "print(f\"Batch Accuracy: {accuracy.item():.4f}\")\n",
    "print(f\"Time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from FFF import FFFInference\n",
    "# from mixer import FFFTrainFixed\n",
    "\n",
    "# def replace_fff_layers(module):\n",
    "#     for name, child in module.named_children():\n",
    "#         if isinstance(child, FFFTrainFixed):\n",
    "#             new_layer = FFFInference(child)\n",
    "#             setattr(module, name, new_layer)\n",
    "#         elif isinstance(child, nn.Module):\n",
    "#             replace_fff_layers(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from FFF import FFFInference\n",
    "from mixer import FFFTrainFixed\n",
    "\n",
    "def replace_fff_layers(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, FFFTrainFixed):\n",
    "            fixed = FFFTrainFixed(child.input_width, child.output_width, 4,)\n",
    "            setattr(module, name, fixed)\n",
    "        elif isinstance(child, nn.Module):\n",
    "            replace_fff_layers(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1_1 = orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1\n",
    "mlp_1_2 = orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2\n",
    "mlp_2_1 = orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_1\n",
    "mlp_2_2 = orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_2\n",
    "\n",
    "new_mlp_1_1 = FFFInference(mlp_1_1)\n",
    "new_mlp_1_2 = FFFInference(mlp_1_2)\n",
    "new_mlp_2_1 = FFFInference(mlp_2_1)\n",
    "new_mlp_2_2 = FFFInference(mlp_2_2)\n",
    "\n",
    "train_mlp_1_1 = FFFTrainFixed(mlp_1_1.input_width, mlp_1_1.output_width, 4,)\n",
    "train_mlp_1_2 = FFFTrainFixed(mlp_1_2.input_width, mlp_1_2.output_width, 4,)\n",
    "train_mlp_2_1 = FFFTrainFixed(mlp_2_1.input_width, mlp_2_1.output_width, 4,)\n",
    "train_mlp_2_2 = FFFTrainFixed(mlp_2_2.input_width, mlp_2_2.output_width, 4,)\n",
    "\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1 = train_mlp_1_1\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2 = train_mlp_1_2\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_1 = train_mlp_2_1\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_2 = train_mlp_2_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "Batch Accuracy: 0.1484\n",
      "Time: 37.884618043899536\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    logits = orig_module.model(batch['inputs'])\n",
    "    end = time.time()\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predictions, batch['targets'])):\n",
    "    predicted_label = cfg.train.labels[pred.item()]\n",
    "    true_label = cfg.train.labels[target.item()]\n",
    "    # print(f\"Sample {i}:\")\n",
    "    # print(f\"  Predicted: {predicted_label}\")\n",
    "    # print(f\"  Actual: {true_label}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = (predictions == batch['targets']).float().mean()\n",
    "print(f\"Batch Accuracy: {accuracy.item():.4f}\")\n",
    "print(f\"Time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n"
     ]
    }
   ],
   "source": [
    "from FFF import FFFInference\n",
    "from mixer import MixerLayer\n",
    "import torch.nn as nn\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "class PnlpMixerSeqClsTrainModule(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "def create_pnlp_mixer_seq_cls(orig_module):\n",
    "\n",
    "    bottleneck_cfg = OmegaConf.create({\n",
    "        \"window_size\": (orig_module.model.pnlp_mixer.bottleneck.in_features // orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width - 1) // 2,\n",
    "        \"feature_size\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width,\n",
    "        \"hidden_dim\": orig_module.model.pnlp_mixer.bottleneck.out_features\n",
    "    })\n",
    "\n",
    "    mixer_cfg = OmegaConf.create({\n",
    "        \"num_mixers\": len(orig_module.model.pnlp_mixer.mixer.mixers),\n",
    "        \"max_seq_len\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width,\n",
    "        \"hidden_dim\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2.input_width,\n",
    "        \"mlp_hidden_dim\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2.output_width\n",
    "    })\n",
    "\n",
    "    seq_cls_cfg = OmegaConf.create({\n",
    "        \"hidden_dim\": orig_module.model.seq_cls.feature_proj.in_features,\n",
    "        \"proj_dim\": orig_module.model.seq_cls.feature_proj.out_features,\n",
    "        \"num_classes\": orig_module.model.seq_cls.cls_proj.out_features\n",
    "    })\n",
    "\n",
    "    new_model = PnlpMixerSeqCls(\n",
    "        bottleneck_cfg=bottleneck_cfg,\n",
    "        mixer_cfg=mixer_cfg,\n",
    "        seq_cls_cfg=seq_cls_cfg\n",
    "    )\n",
    "\n",
    "    new_model.pnlp_mixer.bottleneck = orig_module.model.pnlp_mixer.bottleneck\n",
    "\n",
    "    new_mixer_layers = []\n",
    "    for orig_layer in orig_module.model.pnlp_mixer.mixer.mixers:\n",
    "        new_layer = MixerLayer(\n",
    "            max_seq_len=mixer_cfg.max_seq_len,\n",
    "            hidden_dim=mixer_cfg.hidden_dim,\n",
    "            channel_hidden_dim=mixer_cfg.mlp_hidden_dim,\n",
    "            seq_hidden_dim=mixer_cfg.max_seq_len\n",
    "        )\n",
    "        new_layer.layer_norm_1 = orig_layer.layer_norm_1\n",
    "        new_layer.mlp_1 = FFFInference(orig_layer.mlp_1)\n",
    "        new_layer.layer_norm_2 = orig_layer.layer_norm_2\n",
    "        new_layer.mlp_2 = FFFInference(orig_layer.mlp_2)\n",
    "        new_mixer_layers.append(new_layer)\n",
    "\n",
    "    new_model.pnlp_mixer.mixer.mixers = nn.Sequential(*new_mixer_layers)\n",
    "\n",
    "    new_model.seq_cls = orig_module.model.seq_cls\n",
    "\n",
    "    new_train_module = PnlpMixerSeqClsTrainModule(new_model)\n",
    "\n",
    "    return new_train_module\n",
    "\n",
    "# Usage:\n",
    "new_module = create_pnlp_mixer_seq_cls(orig_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"batch.pkl\", \"rb\") as f:\n",
    "    batch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "Batch Accuracy: 0.8828\n",
      "Time: 27.705037117004395\n"
     ]
    }
   ],
   "source": [
    "orig_module.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    logits = orig_module.model(batch['inputs'])\n",
    "    end = time.time()\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predictions, batch['targets'])):\n",
    "    predicted_label = cfg.train.labels[pred.item()]\n",
    "    true_label = cfg.train.labels[target.item()]\n",
    "    # print(f\"Sample {i}:\")\n",
    "    # print(f\"  Predicted: {predicted_label}\")\n",
    "    # print(f\"  Actual: {true_label}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = (predictions == batch['targets']).float().mean()\n",
    "print(f\"Batch Accuracy: {accuracy.item():.4f}\")\n",
    "print(f\"Time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
