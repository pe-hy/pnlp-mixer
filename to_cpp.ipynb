{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid/miniconda3/envs/to_cpp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from model import PnlpMixerSeqCls, PnlpMixerTokenCls\n",
    "from mixer import FFFTrainFixed\n",
    "from dataset import PnlpMixerDataModule\n",
    "from run import PnlpMixerSeqClsTrainModule, PnlpMixerTokenClsTrainModule\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('cfg/imdb_base.yml')\n",
    "\n",
    "def get_module_cls(type: str): \n",
    "    if type == 'mtop': \n",
    "        return PnlpMixerTokenClsTrainModule\n",
    "    if type == 'matis' or type == 'imdb': \n",
    "        return PnlpMixerSeqClsTrainModule\n",
    "\n",
    "module_cls = get_module_cls(cfg.train.dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'to_cpp/ffft_256_4/model.ckpt'\n",
    "orig_module = module_cls.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    optimizer_cfg=cfg.train.optimizer,\n",
    "    model_cfg=cfg.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PnlpMixerSeqClsTrainModule(\n",
       "  (model): PnlpMixerSeqCls(\n",
       "    (pnlp_mixer): PnlpMixer(\n",
       "      (bottleneck): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (mixer): Mixer(\n",
       "        (mixers): Sequential(\n",
       "          (0): MixerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_1): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=1024, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=1024, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_2): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=256, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=256, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "          )\n",
       "          (1): MixerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_1): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=1024, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=1024, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_2): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=256, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=256, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (seq_cls): SequenceClassificationLayer(\n",
       "      (feature_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (attention_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (cls_proj): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = PnlpMixerDataModule(cfg.vocab, cfg.train, cfg.model.projection)\n",
    "data_module.setup('test')\n",
    "\n",
    "orig_module.eval()\n",
    "\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "\n",
    "batch = next(iter(test_dataloader))\n",
    "\n",
    "device = next(orig_module.parameters()).device\n",
    "batch = {k: v.to(device) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"batch.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(batch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"batch.pkl\", \"rb\") as f:\n",
    "#     batch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1024, 3072])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"inputs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "Batch Accuracy: 0.8828\n",
      "Time: 2.285902500152588\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    logits = orig_module.model(batch['inputs'])\n",
    "    end = time.time()\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predictions, batch['targets'])):\n",
    "    predicted_label = cfg.train.labels[pred.item()]\n",
    "    true_label = cfg.train.labels[target.item()]\n",
    "    # print(f\"Sample {i}:\")\n",
    "    # print(f\"  Predicted: {predicted_label}\")\n",
    "    # print(f\"  Actual: {true_label}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = (predictions == batch['targets']).float().mean()\n",
    "print(f\"Batch Accuracy: {accuracy.item():.4f}\")\n",
    "print(f\"Time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from FFF import FFFInference\n",
    "# from mixer import FFFTrainFixed\n",
    "\n",
    "# def replace_fff_layers(module):\n",
    "#     for name, child in module.named_children():\n",
    "#         if isinstance(child, FFFTrainFixed):\n",
    "#             new_layer = FFFInference(child)\n",
    "#             setattr(module, name, new_layer)\n",
    "#         elif isinstance(child, nn.Module):\n",
    "#             replace_fff_layers(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from FFF import FFFInference\n",
    "from mixer import FFFTrainFixed\n",
    "\n",
    "def replace_fff_layers(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, FFFTrainFixed):\n",
    "            fixed = FFFTrainFixed(child.input_width, child.output_width, 4,)\n",
    "            setattr(module, name, fixed)\n",
    "        elif isinstance(child, nn.Module):\n",
    "            replace_fff_layers(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1_1 = orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1\n",
    "mlp_1_2 = orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2\n",
    "mlp_2_1 = orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_1\n",
    "mlp_2_2 = orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_2\n",
    "\n",
    "new_mlp_1_1 = FFFInference(mlp_1_1)\n",
    "new_mlp_1_2 = FFFInference(mlp_1_2)\n",
    "new_mlp_2_1 = FFFInference(mlp_2_1)\n",
    "new_mlp_2_2 = FFFInference(mlp_2_2)\n",
    "\n",
    "train_mlp_1_1 = FFFTrainFixed(mlp_1_1.input_width, mlp_1_1.output_width, 4,)\n",
    "train_mlp_1_2 = FFFTrainFixed(mlp_1_2.input_width, mlp_1_2.output_width, 4,)\n",
    "train_mlp_2_1 = FFFTrainFixed(mlp_2_1.input_width, mlp_2_1.output_width, 4,)\n",
    "train_mlp_2_2 = FFFTrainFixed(mlp_2_2.input_width, mlp_2_2.output_width, 4,)\n",
    "\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1 = train_mlp_1_1\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2 = train_mlp_1_2\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_1 = train_mlp_2_1\n",
    "orig_module.model.pnlp_mixer.mixer.mixers[1].mlp_2 = train_mlp_2_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "TRAIN\n",
      "torch.Size([256, 256, 1024])\n",
      "AFTER RESHAPE\n",
      "torch.Size([65536, 1024])\n",
      "NEW_LOGITS\n",
      "torch.Size([65536, 1024])\n",
      "TRAIN\n",
      "torch.Size([256, 1024, 256])\n",
      "AFTER RESHAPE\n",
      "torch.Size([262144, 256])\n",
      "NEW_LOGITS\n",
      "torch.Size([262144, 256])\n",
      "Batch Accuracy: 0.1484\n",
      "Time: 37.884618043899536\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    logits = orig_module.model(batch['inputs'])\n",
    "    end = time.time()\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i, (pred, target) in enumerate(zip(predictions, batch['targets'])):\n",
    "    predicted_label = cfg.train.labels[pred.item()]\n",
    "    true_label = cfg.train.labels[target.item()]\n",
    "    # print(f\"Sample {i}:\")\n",
    "    # print(f\"  Predicted: {predicted_label}\")\n",
    "    # print(f\"  Actual: {true_label}\")\n",
    "    # print()\n",
    "\n",
    "accuracy = (predictions == batch['targets']).float().mean()\n",
    "print(f\"Batch Accuracy: {accuracy.item():.4f}\")\n",
    "print(f\"Time: {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
