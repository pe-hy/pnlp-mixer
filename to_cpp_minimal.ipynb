{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need dataset (see dataset_download.txt)\n",
    "# Create conda env for Python 3.7\n",
    "# Run pip install -r requirements.txt\n",
    "# Run pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# Run:    cd to_cpp\n",
    "# Run     pip install .\n",
    "# Might have to do conda install mkl mkl-include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid/miniconda3/envs/to_cpp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from model import PnlpMixerSeqCls, PnlpMixerTokenCls\n",
    "from mixer import FFFTrainFixed\n",
    "from dataset import PnlpMixerDataModule\n",
    "from run import PnlpMixerSeqClsTrainModule, PnlpMixerTokenClsTrainModule\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from FFF import FFFInference\n",
    "from mixer import MixerLayer\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('cfg/imdb_base.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PnlpMixerSeqClsTrainModule(\n",
       "  (model): PnlpMixerSeqCls(\n",
       "    (pnlp_mixer): PnlpMixer(\n",
       "      (bottleneck): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (mixer): Mixer(\n",
       "        (mixers): Sequential(\n",
       "          (0): MixerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_1): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=1024, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=1024, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_2): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=256, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=256, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "          )\n",
       "          (1): MixerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_1): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=1024, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=1024, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp_2): FFFTrainFixed(\n",
       "              (linear_in): Linear(in_features=256, out_features=31, bias=False)\n",
       "              (linear_out): Linear(in_features=31, out_features=256, bias=False)\n",
       "              (activation): GELU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (seq_cls): SequenceClassificationLayer(\n",
       "      (feature_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (attention_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (cls_proj): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'to_cpp/ffft_256_4/model.ckpt'\n",
    "orig_module = PnlpMixerSeqClsTrainModule.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    optimizer_cfg=cfg.train.optimizer,\n",
    "    model_cfg=cfg.model\n",
    ")\n",
    "orig_module.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "# Create a PnlpMixerDataModule instance\n",
    "cfg.train.test_batch_size = 32\n",
    "data_module = PnlpMixerDataModule(cfg.vocab, cfg.train, cfg.model.projection)\n",
    "\n",
    "# Set up the data module for testing\n",
    "data_module.setup('test')\n",
    "\n",
    "# Get the test dataloader\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "\n",
    "# Get the first batch from the test dataloader\n",
    "batch_iterator = iter(test_dataloader)\n",
    "batch = next(batch_iterator)\n",
    "\n",
    "# Get the device of the original module\n",
    "device = next(orig_module.parameters()).device\n",
    "# Move each item in the batch to the device\n",
    "new_batch = {}\n",
    "for key, value in batch.items():\n",
    "    new_batch[key] = value.to(device)\n",
    "\n",
    "batch = new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 3072])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"inputs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "orig_module.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.67 s ± 16.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    logits = orig_module.model(batch['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n",
      "{'num_mixers': 2, 'max_seq_len': 1024, 'hidden_dim': 256, 'mlp_hidden_dim': 256}\n"
     ]
    }
   ],
   "source": [
    "def create_pnlp_mixer_seq_cls(orig_module):\n",
    "\n",
    "    bottleneck_cfg = OmegaConf.create({\n",
    "        \"in_features\": orig_module.model.pnlp_mixer.bottleneck.in_features,\n",
    "        \"out_features\": orig_module.model.pnlp_mixer.bottleneck.out_features,\n",
    "        \"window_size\": (orig_module.model.pnlp_mixer.bottleneck.in_features // orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width - 1) // 2,\n",
    "        \"feature_size\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width,\n",
    "        \"hidden_dim\": orig_module.model.pnlp_mixer.bottleneck.out_features\n",
    "    })\n",
    "\n",
    "    mixer_cfg = OmegaConf.create({\n",
    "        \"num_mixers\": len(orig_module.model.pnlp_mixer.mixer.mixers),\n",
    "        \"max_seq_len\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_1.input_width,\n",
    "        \"hidden_dim\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2.input_width,\n",
    "        \"mlp_hidden_dim\": orig_module.model.pnlp_mixer.mixer.mixers[0].mlp_2.output_width\n",
    "    })\n",
    "\n",
    "    sequence_cls_cfg = OmegaConf.create({\n",
    "        \"hidden_dim\": orig_module.model.seq_cls.feature_proj.in_features,\n",
    "        \"proj_dim\": orig_module.model.seq_cls.feature_proj.out_features,\n",
    "        \"num_classes\": orig_module.model.seq_cls.cls_proj.out_features\n",
    "    })\n",
    "\n",
    "    new_model = PnlpMixerSeqCls(bottleneck_cfg, mixer_cfg, sequence_cls_cfg)\n",
    "\n",
    "    new_model.load_state_dict(orig_module.model.state_dict())\n",
    "\n",
    "    for layer in new_model.pnlp_mixer.mixer.mixers:\n",
    "        layer.mlp_1 = FFFInference(layer.mlp_1)\n",
    "        layer.mlp_2 = FFFInference(layer.mlp_2)\n",
    "\n",
    "    new_module = PnlpMixerSeqClsTrainModule(\n",
    "        optimizer_cfg=orig_module.optimizer_cfg,\n",
    "        model_cfg=OmegaConf.create({\n",
    "            \"bottleneck\": bottleneck_cfg,\n",
    "            \"mixer\": mixer_cfg,\n",
    "            \"sequence_cls\": sequence_cls_cfg\n",
    "        })\n",
    "    )\n",
    "    new_module.model = new_model\n",
    "    return new_module\n",
    "\n",
    "new_module = create_pnlp_mixer_seq_cls(orig_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_module.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46 s ± 80.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    logits = new_module.model(batch['inputs'].to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "to_cpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
